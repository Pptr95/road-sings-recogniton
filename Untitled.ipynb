{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "from torchvision import models\n",
    "#from torchsummary import summary\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, metric, num_epochs=25):\n",
    "    since = time.time()\n",
    "    \n",
    "    epoch_loss_train = []\n",
    "    epoch_acc_train = []\n",
    "    \n",
    "    epoch_loss_test = []\n",
    "    epoch_acc_test = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', metric]:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                epoch_loss_train.append(running_loss / dataset_sizes[phase])\n",
    "                epoch_acc_train.append(running_corrects.double() / dataset_sizes[phase])\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss_train[-1], epoch_acc_train[-1]))\n",
    "            else:\n",
    "                epoch_loss_test.append(running_loss / dataset_sizes[phase])\n",
    "                epoch_acc_test.append(running_corrects.double() / dataset_sizes[phase])\n",
    "                print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss_test[-1], epoch_acc_test[-1]))\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == metric and epoch_acc_test[-1] > best_acc:\n",
    "                best_acc = epoch_acc_test[-1]\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best '+ str(metric) +' accuracy: {:4f}\\n'.format(best_acc))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, (epoch_loss_train, epoch_acc_train), (epoch_loss_test, epoch_acc_test), best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_acc_plot(acc_loss, who, loss=True):\n",
    "    acc = []\n",
    "    for i in range(len(acc_loss[1])):\n",
    "        acc.append(acc_loss[1][i].cpu().item())\n",
    "    if loss:    \n",
    "        plt.plot(range(len(acc_loss[0])), acc_loss[0], label='loss')\n",
    "    plt.plot(range(len(acc_loss[1])), acc, label='accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title(str(who) +': loss and accuracy plot')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(models):\n",
    "    for m in models:\n",
    "        acc = []\n",
    "        for i in range(len(m[2][1])):\n",
    "            acc.append(m[2][1][i].cpu().item())\n",
    "        plt.plot(range(len(m[2][1])), acc, label=str(m[0].__class__.__name__))\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.title('Test accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'traffic'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate and momentum tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lr= 0.001 and m= 0.5\n",
      "Epoch 0/0\n",
      "----------\n",
      "train Loss: 1.3738 Acc: 0.6115\n",
      "val Loss: 0.2404 Acc: 0.9467\n",
      "Training complete in 0m 50s\n",
      "Best val accuracy: 0.946746\n",
      "\n",
      "Using lr= 0.001 and m= 0.7\n",
      "Epoch 0/0\n",
      "----------\n",
      "train Loss: 0.6008 Acc: 0.8461\n",
      "val Loss: 0.0562 Acc: 0.9882\n",
      "Training complete in 0m 51s\n",
      "Best val accuracy: 0.988166\n",
      "\n",
      "Using lr= 0.005 and m= 0\n",
      "Epoch 0/0\n",
      "----------\n",
      "train Loss: 0.4625 Acc: 0.8700\n",
      "val Loss: 0.0373 Acc: 0.9921\n",
      "Training complete in 0m 51s\n",
      "Best val accuracy: 0.992110\n",
      "\n",
      "Using lr= 0.005 and m= 1\n",
      "Epoch 0/0\n",
      "----------\n",
      "train Loss: 0.4124 Acc: 0.8821\n",
      "val Loss: 0.0350 Acc: 0.9875\n",
      "Training complete in 0m 51s\n",
      "Best val accuracy: 0.987508\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(tensor(0.9467, device='cuda:0', dtype=torch.float64), 0.001, 0.5),\n",
       " (tensor(0.9882, device='cuda:0', dtype=torch.float64), 0.001, 0.7),\n",
       " (tensor(0.9921, device='cuda:0', dtype=torch.float64), 0.005, 0.5),\n",
       " (tensor(0.9875, device='cuda:0', dtype=torch.float64), 0.005, 0.7)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = [0.001, 0.005, 0.1]\n",
    "momentum = [0.3, 0.5, 0.7, 0.9]\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 21)\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "accs = []\n",
    "\n",
    "for i in range(2):\n",
    "    print('Using lr: ' + str(learning_rate[0]) + ' and m: ' + str(momentum[i]))\n",
    "    if i == 0:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate[0], momentum=momentum[i])\n",
    "        exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "        model = train_model(model, criterion, optimizer, exp_lr_scheduler, metric='val', num_epochs=10)\n",
    "        accs.append((model[3], learning_rate[0], momentum[i]))\n",
    "    else:\n",
    "        optimizer = optim.SGD(model[0].parameters(), lr=learning_rate[0],momentum=momentum[i])\n",
    "        exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "        model = train_model(model[0], criterion, optimizer, exp_lr_scheduler, metric='val', num_epochs=10)\n",
    "        accs.append((model[3], learning_rate[0], momentum[i]))\n",
    "\n",
    "for i in range(1, len(learning_rate)):\n",
    "    for m in range(len(momentum)):\n",
    "        print('Using lr: ' + str(learning_rate[i]) + ' and m: ' + str(m))\n",
    "        optimizer = optim.SGD(model[0].parameters(), lr=learning_rate[i],momentum=momentum[m])\n",
    "        exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "        model = train_model(model[0], criterion, optimizer, exp_lr_scheduler, metric='val', num_epochs=10)\n",
    "        accs.append((model[3], learning_rate[i], momentum[m]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b1f0d2214f01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mbest_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# best val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# 1 is for learning rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'accs' is not defined"
     ]
    }
   ],
   "source": [
    "best_params = []\n",
    "for i in range(len(accs)):\n",
    "    best_params.append(accs[i][0].cpu().item())\n",
    "# best val\n",
    "learning_rate = accs[np.argmax(best_params)][1] # 1 is for learning rate\n",
    "momentum = accs[np.argmax(best_params)][2] # 2 is for momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just normalization for validation\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'traffic'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'test']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'test']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'test']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1\n",
      "----------\n",
      "train Loss: 0.8303 Acc: 0.7684\n",
      "test Loss: 0.2857 Acc: 0.9365\n",
      "Epoch 1/1\n",
      "----------\n",
      "train Loss: 0.3657 Acc: 0.8948\n",
      "test Loss: 0.1693 Acc: 0.9579\n",
      "Training complete in 1m 39s\n",
      "Best test accuracy: 0.957902\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "#summary(model, (3, 224, 224))\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 21)\n",
    "\n",
    "learning_rate = 0.005\n",
    "momentum = 0.5\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "step_size = 7\n",
    "gamma = 0.1\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
    "\n",
    "model = train_model(model, criterion, optimizer, exp_lr_scheduler, metric='test', num_epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_acc_plot(model[1], who='training') # model_ft[1] is for training, model_ft[2] is for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_acc_plot(model[2], who='testing') # model_ft[1] is for training, model_ft[2] is for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0\n",
      "----------\n",
      "train Loss: 1.2231 Acc: 0.6397\n",
      "test Loss: 0.6306 Acc: 0.8268\n",
      "Training complete in 0m 39s\n",
      "Best test accuracy: 0.826777\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2 = torchvision.models.alexnet(pretrained=True)\n",
    "model2.classifier[6] = nn.Linear(in_features=4096, out_features=21)\n",
    "\n",
    "model2 = model2.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model2.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "model2 = train_model(model2, criterion, optimizer, exp_lr_scheduler, metric='test', num_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0\n",
      "----------\n",
      "train Loss: 1.2471 Acc: 0.6593\n",
      "test Loss: 0.5554 Acc: 0.8744\n",
      "Training complete in 5m 12s\n",
      "Best test accuracy: 0.874396\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model3 = torchvision.models.densenet161(pretrained=True)\n",
    "model3.classifier = nn.Linear(in_features=model3.classifier.in_features, out_features=21)\n",
    "\n",
    "model3 = model3.to(device)\n",
    "\n",
    "learning_rate = 0.001\n",
    "m = 0.9\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model3.parameters(), lr=learning_rate, momentum=momentum)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "model3 = train_model(model3, criterion, optimizer, exp_lr_scheduler, metric='test', num_epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "//TODO\n",
    "- mobile deployment\n",
    "- left and right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare_models([model2, model3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ResNet(\n",
       "   (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "   (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (relu): ReLU(inplace=True)\n",
       "   (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "   (layer1): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (layer2): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "         (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (layer3): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "         (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (layer4): Sequential(\n",
       "     (0): BasicBlock(\n",
       "       (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (downsample): Sequential(\n",
       "         (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "         (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       )\n",
       "     )\n",
       "     (1): BasicBlock(\n",
       "       (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "       (relu): ReLU(inplace=True)\n",
       "       (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "       (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     )\n",
       "   )\n",
       "   (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "   (fc): Linear(in_features=512, out_features=21, bias=True)\n",
       " ),\n",
       " ([0.8302679336200154, 0.365654554837312],\n",
       "  [tensor(0.7684, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.8948, device='cuda:0', dtype=torch.float64)]),\n",
       " ([0.28572292752394274, 0.16925509721349238],\n",
       "  [tensor(0.9365, device='cuda:0', dtype=torch.float64),\n",
       "   tensor(0.9579, device='cuda:0', dtype=torch.float64)]),\n",
       " tensor(0.9579, device='cuda:0', dtype=torch.float64))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
